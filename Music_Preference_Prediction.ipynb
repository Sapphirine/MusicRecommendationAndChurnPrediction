{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "members.csv\n",
      "sample_submission.csv\n",
      "song_extra_info.csv\n",
      "songs.csv\n",
      "submission_lgbm_avg.csv.gz\n",
      "test.csv\n",
      "train.csv\n",
      "\n",
      "Loading data...\n",
      "Done loading...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import datetime\n",
    "import math\n",
    "import gc\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"/Users/yiming/Documents/BigData/final_project/recommeation/input\"]).decode(\"utf8\"))\n",
    "\n",
    "print('Loading data...')\n",
    "data_path = '/Users/yiming/Documents/BigData/final_project/recommeation/input/'\n",
    "train = pd.read_csv(data_path + 'train.csv', dtype={'msno' : 'category',\n",
    "                                                'source_system_tab' : 'category',\n",
    "                                                  'source_screen_name' : 'category',\n",
    "                                                  'source_type' : 'category',\n",
    "                                                  'target' : np.uint8,\n",
    "                                                  'song_id' : 'category'})\n",
    "test = pd.read_csv(data_path + 'test.csv', dtype={'msno' : 'category',\n",
    "                                                'source_system_tab' : 'category',\n",
    "                                                'source_screen_name' : 'category',\n",
    "                                                'source_type' : 'category',\n",
    "                                                'song_id' : 'category'})\n",
    "songs = pd.read_csv(data_path + 'songs.csv',dtype={'genre_ids': 'category',\n",
    "                                                  'language' : 'category',\n",
    "                                                  'artist_name' : 'category',\n",
    "                                                  'composer' : 'category',\n",
    "                                                  'lyricist' : 'category',\n",
    "                                                  'song_id' : 'category'})\n",
    "members = pd.read_csv(data_path + 'members.csv',dtype={'city' : 'category',\n",
    "                                                      'bd' : np.uint8,\n",
    "                                                      'gender' : 'category',\n",
    "                                                      'registered_via' : 'category'},\n",
    "                     parse_dates=['registration_init_time','expiration_date'])\n",
    "songs_extra = pd.read_csv(data_path + 'song_extra_info.csv')\n",
    "print('Done loading...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data merging...\n",
      "Done merging...\n"
     ]
    }
   ],
   "source": [
    "print('Data merging...')\n",
    "\n",
    "\n",
    "train = train.merge(songs, on='song_id', how='left')\n",
    "test = test.merge(songs, on='song_id', how='left')\n",
    "\n",
    "members['membership_days'] = members['expiration_date'].subtract(members['registration_init_time']).dt.days.astype(int)\n",
    "\n",
    "members['registration_year'] = members['registration_init_time'].dt.year\n",
    "members['registration_month'] = members['registration_init_time'].dt.month\n",
    "members['registration_date'] = members['registration_init_time'].dt.day\n",
    "\n",
    "members['expiration_year'] = members['expiration_date'].dt.year\n",
    "members['expiration_month'] = members['expiration_date'].dt.month\n",
    "members['expiration_date'] = members['expiration_date'].dt.day\n",
    "members = members.drop(['registration_init_time'], axis=1)\n",
    "\n",
    "def isrc_to_year(isrc):\n",
    "    if type(isrc) == str:\n",
    "        if int(isrc[5:7]) > 17:\n",
    "            return 1900 + int(isrc[5:7])\n",
    "        else:\n",
    "            return 2000 + int(isrc[5:7])\n",
    "    else:\n",
    "        return np.nan\n",
    "        \n",
    "songs_extra['song_year'] = songs_extra['isrc'].apply(isrc_to_year)\n",
    "songs_extra.drop(['isrc', 'name'], axis = 1, inplace = True)\n",
    "\n",
    "train = train.merge(members, on='msno', how='left')\n",
    "test = test.merge(members, on='msno', how='left')\n",
    "\n",
    "train = train.merge(songs_extra, on = 'song_id', how = 'left')\n",
    "train.song_length.fillna(200000,inplace=True)\n",
    "train.song_length = train.song_length.astype(np.uint32)\n",
    "train.song_id = train.song_id.astype('category')\n",
    "\n",
    "\n",
    "test = test.merge(songs_extra, on = 'song_id', how = 'left')\n",
    "test.song_length.fillna(200000,inplace=True)\n",
    "test.song_length = test.song_length.astype(np.uint32)\n",
    "test.song_id = test.song_id.astype('category')\n",
    "\n",
    "# import gc\n",
    "# del members, songs; gc.collect();\n",
    "\n",
    "print('Done merging...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new features\n",
      "Done adding features\n"
     ]
    }
   ],
   "source": [
    "print (\"Adding new features\")\n",
    "\n",
    "def genre_id_count(x):\n",
    "    if x == 'no_genre_id':\n",
    "        return 0\n",
    "    else:\n",
    "        return x.count('|') + 1\n",
    "\n",
    "train['genre_ids'].fillna('no_genre_id',inplace=True)\n",
    "test['genre_ids'].fillna('no_genre_id',inplace=True)\n",
    "train['genre_ids_count'] = train['genre_ids'].apply(genre_id_count).astype(np.int8)\n",
    "test['genre_ids_count'] = test['genre_ids'].apply(genre_id_count).astype(np.int8)\n",
    "\n",
    "def lyricist_count(x):\n",
    "    if x == 'no_lyricist':\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n",
    "    return sum(map(x.count, ['|', '/', '\\\\', ';']))\n",
    "\n",
    "train['lyricist'].fillna('no_lyricist',inplace=True)\n",
    "test['lyricist'].fillna('no_lyricist',inplace=True)\n",
    "train['lyricists_count'] = train['lyricist'].apply(lyricist_count).astype(np.int8)\n",
    "test['lyricists_count'] = test['lyricist'].apply(lyricist_count).astype(np.int8)\n",
    "\n",
    "def composer_count(x):\n",
    "    if x == 'no_composer':\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n",
    "\n",
    "train['composer'].fillna('no_composer',inplace=True)\n",
    "test['composer'].fillna('no_composer',inplace=True)\n",
    "train['composer_count'] = train['composer'].apply(composer_count).astype(np.int8)\n",
    "test['composer_count'] = test['composer'].apply(composer_count).astype(np.int8)\n",
    "\n",
    "def is_featured(x):\n",
    "    if 'feat' in str(x) :\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "train['artist_name'].fillna('no_artist',inplace=True)\n",
    "test['artist_name'].fillna('no_artist',inplace=True)\n",
    "train['is_featured'] = train['artist_name'].apply(is_featured).astype(np.int8)\n",
    "test['is_featured'] = test['artist_name'].apply(is_featured).astype(np.int8)\n",
    "\n",
    "def artist_count(x):\n",
    "    if x == 'no_artist':\n",
    "        return 0\n",
    "    else:\n",
    "        return x.count('and') + x.count(',') + x.count('feat') + x.count('&')\n",
    "\n",
    "train['artist_count'] = train['artist_name'].apply(artist_count).astype(np.int8)\n",
    "test['artist_count'] = test['artist_name'].apply(artist_count).astype(np.int8)\n",
    "\n",
    "# if artist is same as composer\n",
    "train['artist_composer'] = (train['artist_name'] == train['composer']).astype(np.int8)\n",
    "test['artist_composer'] = (test['artist_name'] == test['composer']).astype(np.int8)\n",
    "\n",
    "\n",
    "# if artist, lyricist and composer are all three same\n",
    "train['artist_composer_lyricist'] = ((train['artist_name'] == train['composer']) & (train['artist_name'] == train['lyricist']) & (train['composer'] == train['lyricist'])).astype(np.int8)\n",
    "test['artist_composer_lyricist'] = ((test['artist_name'] == test['composer']) & (test['artist_name'] == test['lyricist']) & (test['composer'] == test['lyricist'])).astype(np.int8)\n",
    "\n",
    "# is song language 17 or 45. \n",
    "def song_lang_boolean(x):\n",
    "    if '17.0' in str(x) or '45.0' in str(x):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "train['song_lang_boolean'] = train['language'].apply(song_lang_boolean).astype(np.int8)\n",
    "test['song_lang_boolean'] = test['language'].apply(song_lang_boolean).astype(np.int8)\n",
    "\n",
    "\n",
    "_mean_song_length = np.mean(train['song_length'])\n",
    "def smaller_song(x):\n",
    "    if x < _mean_song_length:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "train['smaller_song'] = train['song_length'].apply(smaller_song).astype(np.int8)\n",
    "test['smaller_song'] = test['song_length'].apply(smaller_song).astype(np.int8)\n",
    "\n",
    "# number of times a song has been played before\n",
    "_dict_count_song_played_train = {k: v for k, v in train['song_id'].value_counts().iteritems()}\n",
    "_dict_count_song_played_test = {k: v for k, v in test['song_id'].value_counts().iteritems()}\n",
    "def count_song_played(x):\n",
    "    try:\n",
    "        return _dict_count_song_played_train[x]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            return _dict_count_song_played_test[x]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "    \n",
    "\n",
    "train['count_song_played'] = train['song_id'].apply(count_song_played).astype(np.int64)\n",
    "test['count_song_played'] = test['song_id'].apply(count_song_played).astype(np.int64)\n",
    "\n",
    "# number of times the artist has been played\n",
    "_dict_count_artist_played_train = {k: v for k, v in train['artist_name'].value_counts().iteritems()}\n",
    "_dict_count_artist_played_test = {k: v for k, v in test['artist_name'].value_counts().iteritems()}\n",
    "def count_artist_played(x):\n",
    "    try:\n",
    "        return _dict_count_artist_played_train[x]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            return _dict_count_artist_played_test[x]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "\n",
    "train['count_artist_played'] = train['artist_name'].apply(count_artist_played).astype(np.int64)\n",
    "test['count_artist_played'] = test['artist_name'].apply(count_artist_played).astype(np.int64)\n",
    "\n",
    "\n",
    "print \"Done adding features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train test and validation sets\n",
      "Processed data...\n"
     ]
    }
   ],
   "source": [
    "print (\"Train test and validation sets\")\n",
    "for col in train.columns:\n",
    "    if train[col].dtype == object:\n",
    "        train[col] = train[col].astype('category')\n",
    "        test[col] = test[col].astype('category')\n",
    "\n",
    "\n",
    "X_train = train.drop(['target'], axis=1)\n",
    "y_train = train['target'].values\n",
    "\n",
    "\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "ids = test['id'].values\n",
    "\n",
    "\n",
    "# del train, test; gc.collect();\n",
    "\n",
    "d_train_final = lgb.Dataset(X_train, y_train)\n",
    "watchlist_final = lgb.Dataset(X_train, y_train)\n",
    "print('Processed data...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiming/anaconda2/envs/root_bigdata/lib/python2.7/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/yiming/anaconda2/envs/root_bigdata/lib/python2.7/site-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/Users/yiming/anaconda2/envs/root_bigdata/lib/python2.7/site-packages/lightgbm/basic.py:671: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tvalid_0's auc: 0.7325\n",
      "[10]\tvalid_0's auc: 0.744823\n",
      "[15]\tvalid_0's auc: 0.750811\n",
      "[20]\tvalid_0's auc: 0.755155\n",
      "[25]\tvalid_0's auc: 0.759151\n",
      "[30]\tvalid_0's auc: 0.762612\n",
      "[35]\tvalid_0's auc: 0.76565\n",
      "[40]\tvalid_0's auc: 0.768215\n",
      "[45]\tvalid_0's auc: 0.770507\n",
      "[50]\tvalid_0's auc: 0.77277\n",
      "[55]\tvalid_0's auc: 0.774675\n",
      "[60]\tvalid_0's auc: 0.776417\n",
      "[65]\tvalid_0's auc: 0.778314\n",
      "[70]\tvalid_0's auc: 0.779953\n",
      "[75]\tvalid_0's auc: 0.781495\n",
      "[80]\tvalid_0's auc: 0.783472\n",
      "[85]\tvalid_0's auc: 0.784914\n",
      "[90]\tvalid_0's auc: 0.78634\n",
      "[95]\tvalid_0's auc: 0.787499\n",
      "[100]\tvalid_0's auc: 0.788708\n",
      "[105]\tvalid_0's auc: 0.789773\n",
      "[110]\tvalid_0's auc: 0.791062\n",
      "[115]\tvalid_0's auc: 0.792155\n",
      "[120]\tvalid_0's auc: 0.793052\n",
      "[125]\tvalid_0's auc: 0.794046\n",
      "[130]\tvalid_0's auc: 0.795059\n",
      "[135]\tvalid_0's auc: 0.795905\n",
      "[140]\tvalid_0's auc: 0.796853\n",
      "[145]\tvalid_0's auc: 0.797695\n",
      "[150]\tvalid_0's auc: 0.79856\n",
      "[155]\tvalid_0's auc: 0.799431\n",
      "[160]\tvalid_0's auc: 0.800293\n",
      "[165]\tvalid_0's auc: 0.801094\n",
      "[170]\tvalid_0's auc: 0.802184\n",
      "[175]\tvalid_0's auc: 0.803834\n",
      "[180]\tvalid_0's auc: 0.804375\n",
      "[185]\tvalid_0's auc: 0.804963\n",
      "[190]\tvalid_0's auc: 0.805675\n",
      "[195]\tvalid_0's auc: 0.806466\n",
      "[200]\tvalid_0's auc: 0.807084\n",
      "CPU times: user 20min 35s, sys: 29.8 s, total: 21min 5s\n",
      "Wall time: 5min 10s\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting': 'gbdt',\n",
    "        'learning_rate': 0.3 ,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 108,\n",
    "        'bagging_fraction': 0.95,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction': 0.9,\n",
    "        'feature_fraction_seed': 1,\n",
    "        'max_bin': 256,\n",
    "        'max_depth': 10,\n",
    "        'num_rounds': 200,\n",
    "        'metric' : 'auc'\n",
    "    }\n",
    "\n",
    "%time model_f1 = lgb.train(params, train_set=d_train_final,  valid_sets=watchlist_final, verbose_eval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tvalid_0's auc: 0.7325\n",
      "[10]\tvalid_0's auc: 0.74241\n",
      "[15]\tvalid_0's auc: 0.749878\n",
      "[20]\tvalid_0's auc: 0.75507\n",
      "[25]\tvalid_0's auc: 0.759243\n",
      "[30]\tvalid_0's auc: 0.761553\n",
      "[35]\tvalid_0's auc: 0.763076\n",
      "[40]\tvalid_0's auc: 0.765574\n",
      "[45]\tvalid_0's auc: 0.767157\n",
      "[50]\tvalid_0's auc: 0.768103\n",
      "[55]\tvalid_0's auc: 0.770061\n",
      "[60]\tvalid_0's auc: 0.771767\n",
      "[65]\tvalid_0's auc: 0.774119\n",
      "[70]\tvalid_0's auc: 0.774739\n",
      "[75]\tvalid_0's auc: 0.775916\n",
      "[80]\tvalid_0's auc: 0.776576\n",
      "[85]\tvalid_0's auc: 0.77625\n",
      "[90]\tvalid_0's auc: 0.777008\n",
      "[95]\tvalid_0's auc: 0.778032\n",
      "[100]\tvalid_0's auc: 0.779399\n",
      "[105]\tvalid_0's auc: 0.780479\n",
      "[110]\tvalid_0's auc: 0.780109\n",
      "[115]\tvalid_0's auc: 0.78234\n",
      "[120]\tvalid_0's auc: 0.782495\n",
      "[125]\tvalid_0's auc: 0.78285\n",
      "[130]\tvalid_0's auc: 0.783916\n",
      "[135]\tvalid_0's auc: 0.784634\n",
      "[140]\tvalid_0's auc: 0.785021\n",
      "[145]\tvalid_0's auc: 0.78521\n",
      "[150]\tvalid_0's auc: 0.785676\n",
      "[155]\tvalid_0's auc: 0.786074\n",
      "[160]\tvalid_0's auc: 0.785638\n",
      "[165]\tvalid_0's auc: 0.786813\n",
      "[170]\tvalid_0's auc: 0.788381\n",
      "[175]\tvalid_0's auc: 0.789356\n",
      "[180]\tvalid_0's auc: 0.789124\n",
      "[185]\tvalid_0's auc: 0.790341\n",
      "[190]\tvalid_0's auc: 0.791182\n",
      "[195]\tvalid_0's auc: 0.791704\n",
      "[200]\tvalid_0's auc: 0.792235\n",
      "CPU times: user 1h 7min 15s, sys: 23.5 s, total: 1h 7min 38s\n",
      "Wall time: 11min 23s\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting': 'dart',\n",
    "        'learning_rate': 0.3 ,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 108,\n",
    "        'bagging_fraction': 0.95,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction': 0.9,\n",
    "        'feature_fraction_seed': 1,\n",
    "        'max_bin': 256,\n",
    "        'max_depth': 10,\n",
    "        'num_rounds': 200,\n",
    "        'metric' : 'auc'\n",
    "    }\n",
    "\n",
    "%time model_f2 = lgb.train(params, train_set=d_train_final,  valid_sets=watchlist_final, verbose_eval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "Done making predictions\n"
     ]
    }
   ],
   "source": [
    "print('Making predictions')\n",
    "p_test_1 = model_f1.predict(X_test)\n",
    "p_test_2 = model_f2.predict(X_test)\n",
    "p_test_avg = np.mean([p_test_1, p_test_2], axis = 0)\n",
    "\n",
    "\n",
    "print('Done making predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print type(p_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions Model model of gbdt\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print ('Saving predictions Model model of gbdt')\n",
    "\n",
    "subm = pd.DataFrame()\n",
    "subm['id'] = ids\n",
    "subm['target'] = p_test_avg\n",
    "subm.to_csv(data_path + 'submission_lgbm_avg.csv.gz', compression = 'gzip', index=False, float_format = '%.5f')\n",
    "\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
